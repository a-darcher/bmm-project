{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import itertools\n",
    "from itertools import product\n",
    "from PIL import Image\n",
    "\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from process_model_weights import *\n",
    "from celeb_backbone import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct file indexer\n",
    "\n",
    "classes = list(range(0,10))\n",
    "\n",
    "dataset = [\n",
    "    \"train\",\n",
    "    \"train\", \n",
    "    \"train\",\n",
    "    \"train\",\n",
    "    \"train\", \n",
    "    \"test\",\n",
    "    \"test\",\n",
    "    \"test\", \n",
    "    \"test\",\n",
    "    \"test\",\n",
    "]\n",
    "\n",
    "original_files = [\n",
    " \"057876.jpg\", #002514.jpg\",\n",
    " \"039593.jpg\", #\n",
    " \"094741.jpg\", #\n",
    " \"152801.jpg\", #\n",
    " \"126154.jpg\", #\n",
    " \"034026.jpg\", #\n",
    " \"012857.jpg\", #\n",
    " \"016242.jpg\", #\n",
    " \"153728.jpg\", #\n",
    " \"068982.jpg\",]\n",
    "\n",
    "older_files = [\n",
    "    \"002514.jpg\",     \n",
    "    \"017554.jpg\",     \n",
    "    \"093689.jpg\",     \n",
    "    \"052500.jpg\",     \n",
    "    \"162586.jpg\",     \n",
    "    \"120490.jpg\",     \n",
    "    \"048720.jpg\",     \n",
    "    \"031455.jpg\",     \n",
    "    \"036953.jpg\",     \n",
    "    \"158002.jpg\",     \n",
    "]\n",
    "\n",
    "younger_files = [\n",
    "    \"119296.jpg\",     \n",
    "    \"029394.jpg\",     \n",
    "    \"014392.jpg\",     \n",
    "    \"055349.jpg\",     \n",
    "    \"040676.jpg\",     \n",
    "    \"042867.jpg\",     \n",
    "    \"052814.jpg\",     \n",
    "    \"114366.jpg\",     \n",
    "    \"041553.jpg\",     \n",
    "    \"117606.jpg\",     \n",
    "]\n",
    "\n",
    "c = np.tile(classes, 3)\n",
    "f = np.concatenate([original_files, younger_files, older_files])\n",
    "all_files = pd.DataFrame()\n",
    "all_files[\"classes\"] = c\n",
    "all_files[\"filenames\"] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"classes\"] = classes\n",
    "df[\"og_files\"] = original_files \n",
    "df[\"older_files\"] = older_files\n",
    "df[\"younger_files\"] = younger_files\n",
    "df[\"dataset\"] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "def populate_sequences(sequences, positions, labels, ns_vectors, df):\n",
    "    def generate_combinations(s, p, label, ns_vector):\n",
    "        repeat = s[p[0]]\n",
    "        older_file = df[df[\"classes\"] == repeat][\"older_files\"].iloc[0]\n",
    "        younger_file = df[df[\"classes\"] == repeat][\"younger_files\"].iloc[0]\n",
    "        \n",
    "        s_o = s.copy()\n",
    "        s_y = s.copy()\n",
    "        s_o[p[0]] = older_file\n",
    "        s_o[p[1]] = younger_file\n",
    "        s_y[p[0]] = younger_file\n",
    "        s_y[p[1]] = older_file\n",
    "        \n",
    "        other_positions = [i for i in range(len(s)) if i not in p]\n",
    "        other_classes = [s[i] for i in other_positions]\n",
    "        \n",
    "        choices = []\n",
    "        for cls in other_classes:\n",
    "            choices.append([df[df[\"classes\"] == cls][\"older_files\"].iloc[0], \n",
    "                            df[df[\"classes\"] == cls][\"younger_files\"].iloc[0]])\n",
    "        \n",
    "        new_sequences = []\n",
    "        new_labels = []\n",
    "        new_positions = []\n",
    "        new_ns_vectors = []\n",
    "        \n",
    "        for combo in product(*choices):\n",
    "            new_s_o = s_o.copy()\n",
    "            new_s_y = s_y.copy()\n",
    "            for i, choice in zip(other_positions, combo):\n",
    "                new_s_o[i] = choice\n",
    "                new_s_y[i] = choice\n",
    "            new_sequences.extend([new_s_o, new_s_y])\n",
    "            new_labels.extend([label, label])\n",
    "            new_positions.extend([p, p])\n",
    "            new_ns_vectors.extend([ns_vector, ns_vector])\n",
    "        \n",
    "        return new_sequences, new_labels, new_positions, new_ns_vectors\n",
    "\n",
    "    all_sequences = []\n",
    "    all_labels = []\n",
    "    all_positions = []\n",
    "    all_ns_vectors = []\n",
    "\n",
    "    for s, p, label, ns_vector in zip(sequences, positions, labels, ns_vectors):\n",
    "        seq, lab, pos, ns = generate_combinations(s, p, label, ns_vector)\n",
    "        all_sequences.extend(seq)\n",
    "        all_labels.extend(lab)\n",
    "        all_positions.extend(pos)\n",
    "        all_ns_vectors.extend(ns)\n",
    "    \n",
    "    return all_sequences, all_labels, all_positions, all_ns_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "\n",
    "split = \"test\"\n",
    "train_classes = np.array(df[df[\"dataset\"] == split][\"classes\"])\n",
    "sequences, labels, positions, ns = generate_sequences(train_classes, sequence_length=sequence_length)\n",
    "\n",
    "completed_sequences = []\n",
    "for s in sequences: \n",
    "    temp = []\n",
    "    for c in s:\n",
    "        filename = df[df[\"classes\"] == c][\"og_files\"].iloc[0]\n",
    "        temp.append(filename)\n",
    "\n",
    "    completed_sequences.append(temp)\n",
    "sequences = completed_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebA_embeddings/exp_basic/seq5/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alanadarcher/bmm/bmm-project/process_model_weights.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len filenames: 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:16<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "save_dir = \"celebA_embeddings\"\n",
    "path = Path(f\"{save_dir}/exp_basic/seq{sequence_length}/{split}\")\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "print(path)\n",
    "\n",
    "backbone = VGGEmbeds()\n",
    "\n",
    "checkpoint = 1\n",
    "filenames = [f\"{i:06d}.pt\" for i in range(checkpoint, len(labels) + 1)]\n",
    "print(f\"Len filenames: {len(filenames)}\")\n",
    "\n",
    "dataset = EmbeddingDataset(sequences, labels, positions, ns)\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=4, pin_memory=True, collate_fn=custom_collate)\n",
    "\n",
    "# Process data in batches\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for i, (batch_sequences, batch_labels, batch_positions, batch_ns, ) in enumerate(tqdm(dataloader)):\n",
    "        batch_tensors = []\n",
    "        batch_seq_filenames = []\n",
    "        for sequence in batch_sequences:\n",
    "            sequence_tensors = []\n",
    "            sequence_filenames = []\n",
    "            for file in sequence:\n",
    "                \n",
    "                sequence_filenames.append(file)\n",
    "                sequence_tensors.append(backbone.embedding(file))\n",
    "\n",
    "            batch_tensors.append(torch.stack(sequence_tensors))\n",
    "            batch_seq_filenames.append(sequence_filenames)\n",
    "\n",
    "        batch_tensor = torch.stack(batch_tensors)\n",
    "        \n",
    "        for j, tensor in enumerate(batch_tensor):\n",
    "            idx = i * len(batch_sequences) + j\n",
    "            saver = {\n",
    "                \"sequence\": tensor.cpu(),  # Move back to CPU for saving\n",
    "                \"label\": batch_labels[j],\n",
    "                \"positions\": batch_positions[j],\n",
    "                \"n-distance\": batch_ns[j],\n",
    "                \"sequence_filenames\": batch_seq_filenames[j],\n",
    "            }\n",
    "            \n",
    "            # file1 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            # file2 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            # class1 = all_files[all_files[\"filenames\"] == file1][\"classes\"].iloc[0] \n",
    "            # class2 = all_files[all_files[\"filenames\"] == file2][\"classes\"].iloc[0] \n",
    "\n",
    "            # assert class1 == class2\n",
    "\n",
    "            # dataset = df[df[\"classes\"] == class1][\"dataset\"].iloc[0]\n",
    "            save_path = path / split \n",
    "            save_path.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            torch.save(saver, save_path / filenames[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebA_embeddings/exp_age_final/seq5/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alanadarcher/bmm/bmm-project/process_model_weights.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len filenames: 19200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [04:39<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 5\n",
    "\n",
    "split = \"train\"\n",
    "train_classes = np.array(df[df[\"dataset\"] == split][\"classes\"])\n",
    "sequences, labels, positions, ns = generate_sequences(train_classes, sequence_length=sequence_length)\n",
    "\n",
    "sequences, labels, positions, ns = populate_sequences(sequences, positions, labels, ns, df)\n",
    "\n",
    "assert len(sequences) == len(labels) == len(positions) == len(ns)\n",
    "\n",
    "\n",
    "save_dir = \"celebA_embeddings\"\n",
    "path = Path(f\"{save_dir}/exp_age_final/seq{sequence_length}/{split}\")\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "print(path)\n",
    "\n",
    "backbone = VGGEmbeds()\n",
    "\n",
    "checkpoint = 1\n",
    "filenames = [f\"{i:06d}.pt\" for i in range(checkpoint, len(labels) + 1)]\n",
    "print(f\"Len filenames: {len(filenames)}\")\n",
    "\n",
    "dataset = EmbeddingDataset(sequences, labels, positions, ns)\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=4, pin_memory=True, collate_fn=custom_collate)\n",
    "\n",
    "# Process data in batches\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for i, (batch_sequences, batch_labels, batch_positions, batch_ns, ) in enumerate(tqdm(dataloader)):\n",
    "        batch_tensors = []\n",
    "        batch_seq_filenames = []\n",
    "        for sequence in batch_sequences:\n",
    "            sequence_tensors = []\n",
    "            sequence_filenames = []\n",
    "            for file in sequence:\n",
    "                \n",
    "                sequence_filenames.append(file)\n",
    "                sequence_tensors.append(backbone.embedding(file))\n",
    "\n",
    "            batch_tensors.append(torch.stack(sequence_tensors))\n",
    "            batch_seq_filenames.append(sequence_filenames)\n",
    "\n",
    "        batch_tensor = torch.stack(batch_tensors)\n",
    "        \n",
    "        for j, tensor in enumerate(batch_tensor):\n",
    "            idx = i * len(batch_sequences) + j\n",
    "            saver = {\n",
    "                \"sequence\": tensor.cpu(),  # Move back to CPU for saving\n",
    "                \"label\": batch_labels[j],\n",
    "                \"positions\": batch_positions[j],\n",
    "                \"n-distance\": batch_ns[j],\n",
    "                \"sequence_filenames\": batch_seq_filenames[j],\n",
    "            }\n",
    "            \n",
    "            # file1 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            # file2 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            # class1 = all_files[all_files[\"filenames\"] == file1][\"classes\"].iloc[0] \n",
    "            # class2 = all_files[all_files[\"filenames\"] == file2][\"classes\"].iloc[0] \n",
    "\n",
    "            # assert class1 == class2\n",
    "\n",
    "            # dataset = df[df[\"classes\"] == class1][\"dataset\"].iloc[0]\n",
    "            save_path = path / split \n",
    "            save_path.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            torch.save(saver, save_path / filenames[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebA_embeddings/exp_age_final/seq5/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alanadarcher/bmm/bmm-project/process_model_weights.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len filenames: 19200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [04:33<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 5\n",
    "\n",
    "split = \"test\"\n",
    "test_classes = np.array(df[df[\"dataset\"] == split][\"classes\"])\n",
    "sequences, labels, positions, ns = generate_sequences(test_classes, sequence_length=sequence_length)\n",
    "\n",
    "sequences, labels, positions, ns = populate_sequences(sequences, positions, labels, ns, df)\n",
    "\n",
    "assert len(sequences) == len(labels) == len(positions) == len(ns)\n",
    "\n",
    "\n",
    "save_dir = \"celebA_embeddings\"\n",
    "path = Path(f\"{save_dir}/exp_age_final/seq{sequence_length}/{split}\")\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "print(path)\n",
    "\n",
    "backbone = VGGEmbeds()\n",
    "\n",
    "checkpoint = 1\n",
    "filenames = [f\"{i:06d}.pt\" for i in range(checkpoint, len(labels) + 1)]\n",
    "print(f\"Len filenames: {len(filenames)}\")\n",
    "\n",
    "dataset = EmbeddingDataset(sequences, labels, positions, ns)\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=4, pin_memory=True, collate_fn=custom_collate)\n",
    "\n",
    "# Process data in batches\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for i, (batch_sequences, batch_labels, batch_positions, batch_ns, ) in enumerate(tqdm(dataloader)):\n",
    "        batch_tensors = []\n",
    "        batch_seq_filenames = []\n",
    "        for sequence in batch_sequences:\n",
    "            sequence_tensors = []\n",
    "            sequence_filenames = []\n",
    "            for file in sequence:\n",
    "                \n",
    "                sequence_filenames.append(file)\n",
    "                sequence_tensors.append(backbone.embedding(file))\n",
    "\n",
    "            batch_tensors.append(torch.stack(sequence_tensors))\n",
    "            batch_seq_filenames.append(sequence_filenames)\n",
    "\n",
    "        batch_tensor = torch.stack(batch_tensors)\n",
    "        \n",
    "        for j, tensor in enumerate(batch_tensor):\n",
    "            idx = i * len(batch_sequences) + j\n",
    "            saver = {\n",
    "                \"sequence\": tensor.cpu(),  # Move back to CPU for saving\n",
    "                \"label\": batch_labels[j],\n",
    "                \"positions\": batch_positions[j],\n",
    "                \"n-distance\": batch_ns[j],\n",
    "                \"sequence_filenames\": batch_seq_filenames[j],\n",
    "            }\n",
    "            \n",
    "            # file1 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            # file2 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            # class1 = all_files[all_files[\"filenames\"] == file1][\"classes\"].iloc[0] \n",
    "            # class2 = all_files[all_files[\"filenames\"] == file2][\"classes\"].iloc[0] \n",
    "\n",
    "            # assert class1 == class2\n",
    "\n",
    "            # dataset = df[df[\"classes\"] == class1][\"dataset\"].iloc[0]\n",
    "            save_path = path / split \n",
    "            save_path.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            torch.save(saver, save_path / filenames[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prior effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 5\n",
    "\n",
    "def alter_sequences(df, sequence_length):\n",
    "    sequences, labels, positions, ns = generate_sequences(df['og_files'], sequence_length)\n",
    "\n",
    "    for i in tqdm(range(len(sequences))):\n",
    "\n",
    "        og_file = sequences[i][positions[i][0]]\n",
    "        row = df.loc[df[\"og_files\"] == og_file].iloc[0]\n",
    "        older_filename = row[\"older_files\"]\n",
    "        younger_filename = row[\"younger_files\"]\n",
    "\n",
    "        sequences[i][positions[i][0]] = younger_filename\n",
    "        sequences[i][positions[i][1]] = older_filename\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 531/50400 [00:00<00:09, 5306.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50400/50400 [00:09<00:00, 5413.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 12500, 2: 12500, 1: 12500, 3: 12500})\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 5\n",
    "\n",
    "sequences, labels, positions, ns = generate_sequences(files, sequence_length=sequence_length)\n",
    "sequences = alter_sequences(df, sequence_length)\n",
    "\n",
    "sample_size = 50000\n",
    "\n",
    "samples = uniform_random_samples(ns, sample_size)\n",
    "print(Counter(np.array(ns)[samples]))\n",
    "\n",
    "sequences = np.array(sequences)[samples]\n",
    "labels = np.array(labels)[samples]\n",
    "positions = np.array(positions)[samples]\n",
    "ns = np.array(ns)[samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebA_embeddings/exp_age/seq5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alanadarcher/bmm/bmm-project/process_model_weights.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len filenames: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [12:49<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"celebA_embeddings\"\n",
    "path = Path(f\"{save_dir}/exp_age/seq{sequence_length}\")\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "print(path)\n",
    "\n",
    "backbone = VGGEmbeds()\n",
    "\n",
    "checkpoint = 1\n",
    "filenames = [f\"{i:06d}.pt\" for i in range(checkpoint, len(labels) + 1)]\n",
    "print(f\"Len filenames: {len(filenames)}\")\n",
    "\n",
    "if checkpoint > 1:\n",
    "    sequences = sequences[checkpoint-1:]\n",
    "    labels = labels[checkpoint-1:]\n",
    "    positions = positions[checkpoint-1:]\n",
    "    ns = ns[checkpoint-1:]\n",
    "\n",
    "assert len(filenames) == len(sequences) == len(labels)\n",
    "\n",
    "dataset = EmbeddingDataset(sequences, labels, positions, ns)\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=4, pin_memory=True, collate_fn=custom_collate)\n",
    "\n",
    "# Process data in batches\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for i, (batch_sequences, batch_labels, batch_positions, batch_ns, ) in enumerate(tqdm(dataloader)):\n",
    "        batch_tensors = []\n",
    "        batch_seq_filenames = []\n",
    "        for sequence in batch_sequences:\n",
    "            sequence_tensors = []\n",
    "            sequence_filenames = []\n",
    "            for file in sequence:\n",
    "                \n",
    "                sequence_filenames.append(file)\n",
    "                sequence_tensors.append(backbone.embedding(file))\n",
    "\n",
    "            batch_tensors.append(torch.stack(sequence_tensors))\n",
    "            batch_seq_filenames.append(sequence_filenames)\n",
    "\n",
    "        batch_tensor = torch.stack(batch_tensors)\n",
    "        \n",
    "        for j, tensor in enumerate(batch_tensor):\n",
    "            idx = i * len(batch_sequences) + j\n",
    "            saver = {\n",
    "                \"sequence\": tensor.cpu(),  # Move back to CPU for saving\n",
    "                \"label\": batch_labels[j],\n",
    "                \"positions\": batch_positions[j],\n",
    "                \"n-distance\": batch_ns[j],\n",
    "                \"sequence_filenames\": batch_seq_filenames[j],\n",
    "            }\n",
    "            \n",
    "            file1 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            file2 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            class1 = all_files[all_files[\"filenames\"] == file1][\"classes\"].iloc[0] \n",
    "            class2 = all_files[all_files[\"filenames\"] == file2][\"classes\"].iloc[0] \n",
    "\n",
    "            assert class1 == class2\n",
    "\n",
    "            dataset = df[df[\"classes\"] == class1][\"dataset\"].iloc[0]\n",
    "            save_path = path / dataset \n",
    "            save_path.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            torch.save(saver, save_path / filenames[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 453600/453600 [01:26<00:00, 5247.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 10000, 3: 10000, 5: 10000, 1: 10000, 2: 10000})\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 6\n",
    "\n",
    "sequences, labels, positions, ns = generate_sequences(files, sequence_length=sequence_length)\n",
    "sequences = alter_sequences(df, sequence_length)\n",
    "\n",
    "sample_size = 50000\n",
    "\n",
    "samples = uniform_random_samples(ns, sample_size)\n",
    "print(Counter(np.array(ns)[samples]))\n",
    "\n",
    "sequences = np.array(sequences)[samples]\n",
    "labels = np.array(labels)[samples]\n",
    "positions = np.array(positions)[samples]\n",
    "ns = np.array(ns)[samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebA_embeddings/exp_age/seq6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alanadarcher/bmm/bmm-project/process_model_weights.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len filenames: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [15:20<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"celebA_embeddings\"\n",
    "path = Path(f\"{save_dir}/exp_age/seq{sequence_length}\")\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "print(path)\n",
    "\n",
    "backbone = VGGEmbeds()\n",
    "\n",
    "checkpoint = 1\n",
    "filenames = [f\"{i:06d}.pt\" for i in range(checkpoint, len(labels) + 1)]\n",
    "print(f\"Len filenames: {len(filenames)}\")\n",
    "\n",
    "if checkpoint > 1:\n",
    "    sequences = sequences[checkpoint-1:]\n",
    "    labels = labels[checkpoint-1:]\n",
    "    positions = positions[checkpoint-1:]\n",
    "    ns = ns[checkpoint-1:]\n",
    "\n",
    "assert len(filenames) == len(sequences) == len(labels)\n",
    "\n",
    "dataset = EmbeddingDataset(sequences, labels, positions, ns)\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=4, pin_memory=True, collate_fn=custom_collate)\n",
    "\n",
    "# Process data in batches\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for i, (batch_sequences, batch_labels, batch_positions, batch_ns, ) in enumerate(tqdm(dataloader)):\n",
    "        batch_tensors = []\n",
    "        batch_seq_filenames = []\n",
    "        for sequence in batch_sequences:\n",
    "            sequence_tensors = []\n",
    "            sequence_filenames = []\n",
    "            for file in sequence:\n",
    "                \n",
    "                sequence_filenames.append(file)\n",
    "                sequence_tensors.append(backbone.embedding(file))\n",
    "\n",
    "            batch_tensors.append(torch.stack(sequence_tensors))\n",
    "            batch_seq_filenames.append(sequence_filenames)\n",
    "\n",
    "        batch_tensor = torch.stack(batch_tensors)\n",
    "        \n",
    "        for j, tensor in enumerate(batch_tensor):\n",
    "            idx = i * len(batch_sequences) + j\n",
    "            saver = {\n",
    "                \"sequence\": tensor.cpu(),  # Move back to CPU for saving\n",
    "                \"label\": batch_labels[j],\n",
    "                \"positions\": batch_positions[j],\n",
    "                \"n-distance\": batch_ns[j],\n",
    "                \"sequence_filenames\": batch_seq_filenames[j],\n",
    "            }\n",
    "            \n",
    "            file1 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            file2 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            class1 = all_files[all_files[\"filenames\"] == file1][\"classes\"].iloc[0] \n",
    "            class2 = all_files[all_files[\"filenames\"] == file2][\"classes\"].iloc[0] \n",
    "\n",
    "            assert class1 == class2\n",
    "\n",
    "            dataset = df[df[\"classes\"] == class1][\"dataset\"].iloc[0]\n",
    "            save_path = path / dataset \n",
    "            save_path.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            torch.save(saver, save_path / filenames[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2299572/163296000 [07:26<8:40:49, 5151.92it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m sequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m sequences, labels, positions, ns \u001b[38;5;241m=\u001b[39m generate_sequences(files, sequence_length\u001b[38;5;241m=\u001b[39msequence_length)\n\u001b[0;32m----> 4\u001b[0m sequences \u001b[38;5;241m=\u001b[39m alter_sequences(df, sequence_length)\n\u001b[1;32m      6\u001b[0m sample_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50000\u001b[39m\n\u001b[1;32m      8\u001b[0m samples \u001b[38;5;241m=\u001b[39m uniform_random_samples(ns, sample_size)\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36malter_sequences\u001b[0;34m(df, sequence_length)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sequences))):\n\u001b[1;32m      8\u001b[0m     og_file \u001b[38;5;241m=\u001b[39m sequences[i][positions[i][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m----> 9\u001b[0m     row \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mog_files\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m og_file]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m     older_filename \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124molder_files\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m     younger_filename \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myounger_files\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pml/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[0;32m~/miniconda3/envs/pml/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmp_method(other, operator\u001b[38;5;241m.\u001b[39meq)\n",
      "File \u001b[0;32m~/miniconda3/envs/pml/lib/python3.12/site-packages/pandas/core/series.py:6121\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m-> 6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/pml/lib/python3.12/site-packages/pandas/core/series.py:6231\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   6228\u001b[0m \u001b[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[1;32m   6229\u001b[0m \u001b[38;5;66;03m#  JSONArray tests\u001b[39;00m\n\u001b[1;32m   6230\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 6231\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(result, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   6232\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   6234\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   6235\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pml/lib/python3.12/site-packages/pandas/core/series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pml/lib/python3.12/site-packages/pandas/core/construction.py:555\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    552\u001b[0m     object_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;66;03m# extract ndarray or ExtensionArray, ensure we have no NumpyExtensionArray\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m data \u001b[38;5;241m=\u001b[39m extract_array(data, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pml/lib/python3.12/site-packages/pandas/core/construction.py:461\u001b[0m, in \u001b[0;36mextract_array\u001b[0;34m(obj, extract_numpy, extract_range)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_array\u001b[39m(\n\u001b[1;32m    417\u001b[0m     obj: T, extract_numpy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, extract_range: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    418\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T \u001b[38;5;241m|\u001b[39m ArrayLike:\n\u001b[1;32m    419\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    Extract the ndarray or ExtensionArray from a Series or Index.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    array([1, 2, 3])\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m     typ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01min\u001b[39;00m _typs:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# i.e. isinstance(obj, (ABCIndex, ABCSeries))\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrangeindex\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sequence_length = 10\n",
    "\n",
    "sequences, labels, positions, ns = generate_sequences(files, sequence_length=sequence_length)\n",
    "sequences = alter_sequences(df, sequence_length)\n",
    "\n",
    "sample_size = 50000\n",
    "\n",
    "samples = uniform_random_samples(ns, sample_size)\n",
    "print(Counter(np.array(ns)[samples]))\n",
    "\n",
    "sequences = np.array(sequences)[samples]\n",
    "labels = np.array(labels)[samples]\n",
    "positions = np.array(positions)[samples]\n",
    "ns = np.array(ns)[samples]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celebA_embeddings/exp_age/seq8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alanadarcher/bmm/bmm-project/process_model_weights.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len filenames: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [19:45<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"celebA_embeddings\"\n",
    "path = Path(f\"{save_dir}/exp_age/seq{sequence_length}\")\n",
    "path.mkdir(exist_ok=True, parents=True)\n",
    "print(path)\n",
    "\n",
    "backbone = VGGEmbeds()\n",
    "\n",
    "checkpoint = 1\n",
    "filenames = [f\"{i:06d}.pt\" for i in range(checkpoint, len(labels) + 1)]\n",
    "print(f\"Len filenames: {len(filenames)}\")\n",
    "\n",
    "if checkpoint > 1:\n",
    "    sequences = sequences[checkpoint-1:]\n",
    "    labels = labels[checkpoint-1:]\n",
    "    positions = positions[checkpoint-1:]\n",
    "    ns = ns[checkpoint-1:]\n",
    "\n",
    "assert len(filenames) == len(sequences) == len(labels)\n",
    "\n",
    "dataset = EmbeddingDataset(sequences, labels, positions, ns)\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=4, pin_memory=True, collate_fn=custom_collate)\n",
    "\n",
    "# Process data in batches\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for i, (batch_sequences, batch_labels, batch_positions, batch_ns, ) in enumerate(tqdm(dataloader)):\n",
    "        batch_tensors = []\n",
    "        batch_seq_filenames = []\n",
    "        for sequence in batch_sequences:\n",
    "            sequence_tensors = []\n",
    "            sequence_filenames = []\n",
    "            for file in sequence:\n",
    "                \n",
    "                sequence_filenames.append(file)\n",
    "                sequence_tensors.append(backbone.embedding(file))\n",
    "\n",
    "            batch_tensors.append(torch.stack(sequence_tensors))\n",
    "            batch_seq_filenames.append(sequence_filenames)\n",
    "\n",
    "        batch_tensor = torch.stack(batch_tensors)\n",
    "        \n",
    "        for j, tensor in enumerate(batch_tensor):\n",
    "            idx = i * len(batch_sequences) + j\n",
    "            saver = {\n",
    "                \"sequence\": tensor.cpu(),  # Move back to CPU for saving\n",
    "                \"label\": batch_labels[j],\n",
    "                \"positions\": batch_positions[j],\n",
    "                \"n-distance\": batch_ns[j],\n",
    "                \"sequence_filenames\": batch_seq_filenames[j],\n",
    "            }\n",
    "            \n",
    "            file1 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            file2 = np.array(batch_seq_filenames[j])[batch_positions[j][1]]\n",
    "            class1 = all_files[all_files[\"filenames\"] == file1][\"classes\"].iloc[0] \n",
    "            class2 = all_files[all_files[\"filenames\"] == file2][\"classes\"].iloc[0] \n",
    "\n",
    "            assert class1 == class2\n",
    "\n",
    "            dataset = df[df[\"classes\"] == class1][\"dataset\"].iloc[0]\n",
    "            save_path = path / dataset \n",
    "            save_path.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            torch.save(saver, save_path / filenames[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
